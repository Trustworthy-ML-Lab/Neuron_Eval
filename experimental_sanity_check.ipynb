{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5defd09-da1e-4a07-a9ef-6e432b327fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from torcheval.metrics.functional import binary_auprc\n",
    "\n",
    "import utils\n",
    "import metrics\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283c4ea9",
   "metadata": {},
   "source": [
    "## Test parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f952674-3a3e-49c1-b93c-8e325da8c032",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "batch_size = 256\n",
    "activations_dir = 'saved_activations'\n",
    "epsilon = 0.001\n",
    "n_samples = 1 #how many different samples for c_t^+/c_t^- we take\n",
    "\n",
    "setting = 3 #which setting to run, following Appendix F.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76bb2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if setting == 1:\n",
    "    dataset_name = \"imagenet_val\"\n",
    "    target_name = \"vit_b_16_imagenet\"\n",
    "    target_layer = \"heads\"\n",
    "    activation_fn = \"softmax\"\n",
    "    superclass_concepts = True\n",
    "    superclass_neurons = True\n",
    "    final_layer = True\n",
    "    test_alpha = \"best\"\n",
    "\n",
    "elif setting == 2:\n",
    "    dataset_name = \"imagenet_val\"\n",
    "    target_name = \"resnet50_imagenet\"\n",
    "    target_layer = \"layer4\"\n",
    "    activation_fn = None\n",
    "    superclass_concepts = True\n",
    "    superclass_neurons = False\n",
    "    final_layer = False\n",
    "    test_alpha = 0.005\n",
    "\n",
    "elif setting == 3:\n",
    "    dataset_name = \"places365_val\"\n",
    "    target_name = \"resnet18_places365\"\n",
    "    target_layer = \"fc\"\n",
    "    activation_fn = \"softmax\"\n",
    "    superclass_concepts = False\n",
    "    superclass_neurons = False\n",
    "    final_layer = True\n",
    "    test_alpha = \"best\"\n",
    "\n",
    "elif setting == 4:\n",
    "    dataset_name = \"places365_val\"\n",
    "    target_name = \"resnet18_places365\"\n",
    "    target_layer = \"layer4\"\n",
    "    activation_fn = None\n",
    "    superclass_concepts = False\n",
    "    superclass_neurons = False\n",
    "    final_layer = False\n",
    "    test_alpha = 0.005\n",
    "\n",
    "elif setting == 5:\n",
    "    dataset_name = \"cub_test\"\n",
    "    target_name = \"cub_cbm\"\n",
    "    activation_fn = \"sigmoid\"\n",
    "    superclass_concepts = False\n",
    "    superclass_neurons = False\n",
    "    final_layer = True\n",
    "    test_alpha = \"best\"\n",
    "\n",
    "elif setting == 6:\n",
    "    dataset_name = \"cub_test\"\n",
    "    target_name = \"cub_linear_probe\"\n",
    "    activation_fn = \"sigmoid\"\n",
    "    superclass_concepts = False\n",
    "    superclass_neurons = False\n",
    "    final_layer = True\n",
    "    test_alpha = \"best\"\n",
    "\n",
    "elif setting == 7:\n",
    "    dataset_name = \"openwebtext_subset\"\n",
    "    target_name = \"gpt2-small\"\n",
    "    activation_fn = None #running softmax inside the model since only including subset of output toks\n",
    "    superclass_concepts = False\n",
    "    superclass_neurons = False\n",
    "    final_layer = True\n",
    "    test_alpha = \"best\"\n",
    "    batch_size = 16 #overriding since llm uses more memory\n",
    "\n",
    "elif setting == 8:\n",
    "    dataset_name = \"openwebtext_subset\"\n",
    "    target_name = \"gpt2-xl\"\n",
    "    activation_fn = None #running softmax inside the model since only including subset of output toks\n",
    "    superclass_concepts = False\n",
    "    superclass_neurons = False\n",
    "    final_layer = True\n",
    "    test_alpha = \"best\"\n",
    "    batch_size = 16 #overriding since llm uses more memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29000ac3-50ef-405e-b6b2-cba4895dcdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess = data_utils.get_target_model(target_name, device=device)\n",
    "dataset = data_utils.get_data(dataset_name, preprocess)\n",
    "if dataset_name != \"openwebtext_subset\":\n",
    "    pil_data = data_utils.get_data(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7039f777-62b9-41dc-a77d-58b854c6667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == \"cub_test\":\n",
    "    concept_activations, text = utils.get_cub_concept_labels(dataset, device, batch_size)\n",
    "    neuron_activations = utils.get_cub_concept_preds(model, dataset, device, batch_size)\n",
    "elif dataset_name == \"openwebtext_subset\":\n",
    "    concept_activations, neuron_activations = utils.get_llm_ct_ak(model, dataset, device, batch_size)\n",
    "else:\n",
    "    concept_activations, text = utils.get_onehot_labels(dataset_name, device, superclass_concepts)\n",
    "    layer_save_path = '{}/{}_{}/{}/'.format(activations_dir, target_name, dataset_name, target_layer)\n",
    "    neuron_activations = utils.save_summary_activations(model, dataset, device, target_layer, batch_size, layer_save_path)\n",
    "\n",
    "\n",
    "if activation_fn == \"softmax\":\n",
    "    neuron_activations = torch.nn.functional.softmax(neuron_activations, dim=1)\n",
    "elif activation_fn == \"sigmoid\":\n",
    "    neuron_activations = torch.nn.functional.sigmoid(neuron_activations)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(concept_activations.shape, neuron_activations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c0c372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check prediction accuracy to make sure loading works, only works for some settings\n",
    "#print(torch.mean((neuron_activations > 0.5).float() == concept_activations, dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f05363",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name != \"openwebtext_subset\":\n",
    "    #check to see inputs and concept labels loaded correctly\n",
    "    img_id = 2500\n",
    "    plt.imshow(pil_data[img_id][0])\n",
    "    vals, ids = torch.sort(concept_activations[img_id], descending=True)\n",
    "    print(\"Top concepts:\")\n",
    "    for id in ids[:5]:\n",
    "        print(text[id], concept_activations[img_id, id].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34ce234-1bf4-45db-adec-e726f51a4a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating superclass neurons, only for imagenet final layer\n",
    "if superclass_neurons:\n",
    "    assert(final_layer==True)\n",
    "    assert(dataset_name==\"imagenet_val\")\n",
    "    with open('data/imagenet_superclass_to_ids.json', 'r') as f:\n",
    "        superclass_to_id = json.load(f)\n",
    "    \n",
    "    new_activations = []\n",
    "    for sclass in superclass_to_id.keys():\n",
    "        subclasses = superclass_to_id[sclass]\n",
    "        new_activations.append(torch.sum(torch.stack([neuron_activations[:, i] for i in subclasses], dim=0), dim=0))\n",
    "    new_activations = torch.stack(new_activations, dim=1)\n",
    "    print(neuron_activations.shape, new_activations.shape)\n",
    "    neuron_activations = torch.cat([neuron_activations, new_activations], dim=1)\n",
    "\n",
    "if final_layer:\n",
    "    correct = torch.arange(neuron_activations.shape[1])\n",
    "else:\n",
    "    #explanation is the concept that maximizes IoU\n",
    "    similarities = metrics.iou(neuron_activations, concept_activations, alpha=test_alpha)\n",
    "    correct = torch.argmax(similarities, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4a2447",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5683c0ee",
   "metadata": {},
   "source": [
    "### Split neurons into 5% validation and 95% test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7e9ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = concept_activations.shape[1]\n",
    "neurons = torch.randperm(neuron_activations.shape[1])\n",
    "val_neurons = neurons[:int(0.05*len(neurons))].sort()[0]\n",
    "val_correct = correct[val_neurons]\n",
    "val_correct = torch.nn.functional.one_hot(val_correct, num_classes=num_classes).to(device)\n",
    "\n",
    "test_neurons = neurons[int(0.05*len(neurons)):].sort()[0]\n",
    "test_correct = correct[test_neurons]\n",
    "test_correct = torch.nn.functional.one_hot(test_correct, num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eb58d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_missing = []\n",
    "concepts_extra = []\n",
    "for _ in range(n_samples):\n",
    "    mask = torch.rand(concept_activations.shape, device=device) > 0.5\n",
    "    concepts_missing.append((concept_activations*mask).cpu())\n",
    "\n",
    "    cutoff = torch.sum(concept_activations, dim=0, keepdims=True)/(concept_activations.shape[0]-torch.sum(concept_activations, dim=0, keepdims=True))\n",
    "    extra = torch.rand(concept_activations.shape, device=device) < cutoff\n",
    "    concepts_extra.append(torch.clamp(concept_activations + extra, max=1).cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923e9ffb-b449-4672-b45d-c7e7330d63c6",
   "metadata": {},
   "source": [
    "## Testing different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7daab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(missing_diff, extra_diff):\n",
    "    missing_reduced = torch.mean((missing_diff<-epsilon).float())*100\n",
    "    print(\"Missing Labels Test: Avg Score Diff:{:.4f}, Decrease Acc: {:.2f}%\".format(missing_diff.mean(), missing_reduced))\n",
    "    extra_reduced = torch.mean((extra_diff<-epsilon).float())*100\n",
    "    print(\"Extra Labels Test: Avg Score Diff:{:.4f}, Decrease Acc: {:.2f}%\".format(extra_diff.mean(), extra_reduced))\n",
    "\n",
    "def run_test(explanation_fn, min_val=None, max_val=None):\n",
    "    similarities = explanation_fn(neuron_activations[:, test_neurons], concept_activations)\n",
    "    auc = binary_auprc(similarities.flatten(), test_correct.flatten())\n",
    "    print(\"Test AUPRC: {:.7f}\".format(auc))\n",
    "\n",
    "    correct_sims = torch.sum(similarities*test_correct, dim=1)\n",
    "\n",
    "    missing_c_sims = []\n",
    "    corr_miss_c_sims = []\n",
    "    for c_missing in concepts_missing:\n",
    "        missing_c_sim = explanation_fn(neuron_activations[:, test_neurons], c_missing.to(device))\n",
    "        missing_c_sims.append(missing_c_sim)\n",
    "        corr_miss_c_sims.append(torch.sum(missing_c_sim*test_correct, dim=1))\n",
    "\n",
    "    extra_c_sims = []\n",
    "    corr_extra_c_sims = []\n",
    "    for c_extra in concepts_extra:\n",
    "        extra_c_sim = explanation_fn(neuron_activations[:, test_neurons], c_extra.to(device))\n",
    "        extra_c_sims.append(extra_c_sim)\n",
    "        corr_extra_c_sims.append(torch.sum(extra_c_sim*test_correct, dim=1))\n",
    "    \n",
    "    if min_val==None:\n",
    "        min_val = torch.min(torch.cat([similarities]+missing_c_sims+extra_c_sims, dim=0))\n",
    "    if max_val==None:\n",
    "        max_val = torch.max(torch.cat([similarities]+missing_c_sims+extra_c_sims, dim=0))\n",
    "\n",
    "    print(\"Original avg:{:.4f}\".format(torch.mean(correct_sims)))\n",
    "    #average across samples\n",
    "    corr_miss_c_sims = torch.mean(torch.stack(corr_miss_c_sims, dim=0), dim=0)\n",
    "    corr_extra_c_sims = torch.mean(torch.stack(corr_extra_c_sims, dim=0), dim=0)\n",
    "\n",
    "    missing_diff = (corr_miss_c_sims-correct_sims)/(max_val-min_val)\n",
    "    extra_diff = (corr_extra_c_sims-correct_sims)/(max_val-min_val)\n",
    "    print_results(missing_diff, extra_diff)\n",
    "    \n",
    "def fast_sims(explanation_fn, concept_acts):\n",
    "    correct_ids = torch.argmax(test_correct, dim=1)\n",
    "    correct_sims = []\n",
    "    for i in range(len(test_neurons)):\n",
    "        sims = explanation_fn(neuron_activations[:, test_neurons[i]:test_neurons[i]+1],\n",
    "                                            concept_acts[:, correct_ids[i]:correct_ids[i]+1])\n",
    "        correct_sims.append(sims[0,0])\n",
    "    correct_sims = torch.stack(correct_sims, dim=0)\n",
    "    return correct_sims\n",
    "\n",
    "def run_test_fast(explanation_fn, min_val, max_val):\n",
    "    correct_sims = fast_sims(explanation_fn, concept_activations)\n",
    "    \n",
    "    corr_miss_c_sims = []\n",
    "    for c_missing in concepts_missing:\n",
    "        corr_miss_c_sims.append(fast_sims(explanation_fn, c_missing.to(device)))\n",
    "    corr_miss_c_sims = torch.mean(torch.stack(corr_miss_c_sims, dim=0), dim=0)\n",
    "\n",
    "    corr_extra_c_sims = []\n",
    "    for c_extra in concepts_extra:\n",
    "        corr_extra_c_sims.append(fast_sims(explanation_fn, c_extra.to(device)))\n",
    "    corr_extra_c_sims = torch.mean(torch.stack(corr_extra_c_sims, dim=0), dim=0)\n",
    "\n",
    "    missing_diff = (corr_miss_c_sims-correct_sims)/(max_val-min_val)\n",
    "    extra_diff = (corr_extra_c_sims-correct_sims)/(max_val-min_val)\n",
    "    print_results(missing_diff, extra_diff)\n",
    "\n",
    "def find_best_alpha(explanation_fn, min_val=None, max_val=None, use_fast=False, test_alpha=test_alpha):\n",
    "    \"\"\"\n",
    "    for fns with only an alpha parameter\n",
    "    \"\"\"\n",
    "    \n",
    "    if test_alpha == \"best\":\n",
    "        best_auc = -1\n",
    "        best_alpha = 0\n",
    "        for alpha in [0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5]:\n",
    "            similarities = explanation_fn(neuron_activations[:, val_neurons], concept_activations, alpha=alpha)\n",
    "            auc = binary_auprc(similarities.flatten(), val_correct.flatten())\n",
    "            if auc > best_auc:\n",
    "                best_auc = auc\n",
    "                best_alpha = alpha\n",
    "                #print(\"Alpha: {}, Val AUC: {:.7f}\".format(alpha, auc))\n",
    "        print(\"Best Alpha: {}\".format(best_alpha))\n",
    "    else:\n",
    "        best_alpha = test_alpha\n",
    "        print(\"Using Alpha = {}\".format(best_alpha))\n",
    "\n",
    "    if use_fast:\n",
    "        run_test_fast(explanation_fn=lambda x, y: explanation_fn(x, y, alpha=best_alpha),\n",
    "                        min_val=min_val, max_val=max_val)\n",
    "    else:\n",
    "        run_test(explanation_fn=lambda x, y: explanation_fn(x, y, alpha=best_alpha),\n",
    "                        min_val=min_val, max_val=max_val)\n",
    "\n",
    "def find_best_alpha_lam(explanation_fn, min_val=None, max_val=None, test_alpha=test_alpha):\n",
    "    best_auc = -1\n",
    "    if test_alpha == \"best\":\n",
    "        best_alpha = 0\n",
    "        best_lam = 0\n",
    "        for alpha in [0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5]:\n",
    "            for lam in [0.01*i for i in range(101)]:\n",
    "                similarities = explanation_fn(neuron_activations[:, val_neurons], concept_activations, alpha=alpha, lam=lam)\n",
    "                auc = binary_auprc(similarities.flatten(), val_correct.flatten())\n",
    "                if auc > best_auc:\n",
    "                    best_auc = auc\n",
    "                    best_alpha = alpha\n",
    "                    best_lam = lam\n",
    "                    #print(\"alpha={}, lam={}, Val AUC: {:.7f}\".format(alpha, lam, auc))\n",
    "        print(\"Best alpha={}, Best lam={}\".format(best_alpha, best_lam))\n",
    "    else:\n",
    "        best_lam = 0\n",
    "        best_alpha = test_alpha\n",
    "        for lam in [0.01*i for i in range(101)]:\n",
    "            similarities = explanation_fn(neuron_activations[:, val_neurons], concept_activations, alpha=test_alpha, lam=lam)\n",
    "            auc = binary_auprc(similarities.flatten(), val_correct.flatten())\n",
    "            if auc > best_auc:\n",
    "                best_auc = auc\n",
    "                best_lam = lam\n",
    "        print(\"Best alpha={}, Best lam={}\".format(best_alpha, best_lam))\n",
    "    \n",
    "    run_test(explanation_fn=lambda x, y: explanation_fn(x, y, alpha=best_alpha, lam=best_lam),\n",
    "                       min_val=min_val, max_val=max_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68b679d",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21019b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_alpha(metrics.recall, min_val=0, max_val=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b5e543",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0162defc",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_alpha(metrics.precision, min_val=0, max_val=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab61815",
   "metadata": {},
   "source": [
    "### F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e9b3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_alpha(metrics.f1_score, min_val=0, max_val=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701d0540",
   "metadata": {},
   "source": [
    "### IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c33f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_alpha(metrics.iou, min_val=0, max_val=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018b3627",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40334fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_alpha(metrics.accuracy, min_val=0, max_val=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792f4276",
   "metadata": {},
   "source": [
    "### Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac4a372",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "find_best_alpha(metrics.balanced_accuracy, min_val=0, max_val=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1e4a90-5fca-409f-89ef-8ba7f9dc2a9d",
   "metadata": {},
   "source": [
    "### Inverse Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2488518e-3676-4523-a6c4-35810a9c1c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_alpha(metrics.inverse_balanced_accuracy, min_val=0, max_val=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43dd853",
   "metadata": {},
   "source": [
    "### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5730afe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_alpha(metrics.auc, min_val=0, max_val=1, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e735b24f",
   "metadata": {},
   "source": [
    "### Inverse AUC (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f257c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test_fast(metrics.inverse_auc, min_val=0, max_val=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a96211",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163c4274",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(metrics.correlation, min_val=-1, max_val=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72ca3ef-716c-470f-a788-3881df18032b",
   "metadata": {},
   "source": [
    "### Correlation top-and-random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829b8cea-d1e9-46df-9a37-cea27fe7717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(metrics.correlation_top_and_random, min_val=-1, max_val=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153fcdb0-ee51-4840-9e74-7a29b2cf8f71",
   "metadata": {},
   "source": [
    "### Spearman Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a602b-1df4-40d4-9245-5705221fb2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(metrics.spearman_correlation, min_val=-1, max_val=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65261030-0a02-412e-ac5d-f36ea33ae6b8",
   "metadata": {},
   "source": [
    "### Spearman Correlation top-and-random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b449ae72-11d1-49b1-a8cd-cd6313e62ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(metrics.spearman_correlation_top_and_random, min_val=-1, max_val=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6f98ed",
   "metadata": {},
   "source": [
    "### Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca75062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(metrics.cos_sim, min_val=-1, max_val=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502833b0-1a77-44a3-9b75-43cef6f26ed7",
   "metadata": {},
   "source": [
    "### WPMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18968784",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_alpha_lam(metrics.wpmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e99431-609f-498c-8c96-d2bed093a943",
   "metadata": {},
   "source": [
    "### MAD (Mean Activation Difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1651db3b-eea0-4f11-8d67-eb32e8277416",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_test(metrics.mad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3e1bb0",
   "metadata": {},
   "source": [
    "### AUPRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1d9f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slower than others\n",
    "find_best_alpha(metrics.auprc, min_val=0, max_val=1, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0ed9d0",
   "metadata": {},
   "source": [
    "### Inverse AUPRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a0bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test_fast(metrics.inverse_auprc, min_val=0, max_val=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d57b290",
   "metadata": {},
   "source": [
    "## Appendix: Combination Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa78a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_alpha(metrics.combined_auc, min_val=0, max_val=1, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24665db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_alpha(metrics.combined_balanced_acc, min_val=0, max_val=1, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d668f149",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_alpha(metrics.recall_auc, min_val=0, max_val=1, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680e57b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_alpha(metrics.recall_inv_auc, min_val=0, max_val=1, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f1e87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_alpha(metrics.precision_bal_acc, min_val=0, max_val=1, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e49e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_alpha(metrics.precision_inverse_bal_acc, min_val=0, max_val=1, use_fast=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NeuronEval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
